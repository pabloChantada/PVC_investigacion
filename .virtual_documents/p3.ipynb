


import os

# Imprime el directorio actual de trabajo
print("Directorio actual:", os.getcwd())

# Verifica si el directorio existe
ruta_base = "/home/clown/3-year/computer_vision/roads"
if os.path.exists(ruta_base):
    print("La ruta base existe")
else:
    print("La ruta base no existe")


import numpy as np
import skimage.io as io
import glob
import cv2

# Ruta a tus imágenes y máscaras
image_paths = glob.glob("/home/clown/3-year/computer_vision/roads/sat/*.tif*")
mask_paths = glob.glob("/home/clown/3-year/computer_vision/roads/gt/*.tif*")

# image_paths = glob.glob("/home/clown/3-year/computer_vision/p3/sat/*.tiff")
# mask_paths = glob.glob("/home/clown/3-year/computer_vision/p3/gt/*.tif")

# Cargar imágenes y máscaras
images = [io.imread(img_path) for img_path in image_paths]
masks = [io.imread(mask_path) for mask_path in mask_paths]

# Redimensionar
if len(images) > 0 and len(masks) > 0:
    images = [cv2.resize(img, (256, 256)) for img in images]
    masks = [cv2.resize(mask, (256, 256)) for mask in masks]
    print("Redimensionamiento completado.")
else:
    print("No se cargaron imágenes o máscaras.")




def extract_features(image):
    # Vector de características RGB
    r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]
    # Matriz de valores RGB para cada pixel
    rgb_features = np.stack((r.flatten(), g.flatten(), b.flatten()), axis=1)
    
    # Conversión a escala de grises y extracción de bordes con Canny
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 150, 300).flatten()

    # Concatenar RGB y bordes en un solo vector de características
    features = np.concatenate((rgb_features, edges[:, np.newaxis]), axis=1)
    return features

# Aplicar extracción de características a todas las imágenes
features = [extract_features(img) for img in images]




HACER downsampling


from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from xgboost import XGBClassifier

# Aplanar las máscaras para obtener etiquetas (1 para carretera, 0 para no-carretera)
labels = [mask.flatten() for mask in masks]

# Inicialización del clasificador y k-fold cross-validation
kf = KFold(n_splits=8)
metrics = {"accuracy": [], "precision": [], "recall": [], "f1": []}

for train_index, test_index in kf.split(features):
    X_train = np.vstack([features[i] for i in train_index])
    y_train = np.hstack([labels[i] for i in train_index])
    X_test = np.vstack([features[i] for i in test_index])
    y_test = np.hstack([labels[i] for i in test_index])
    
    # Entrenar clasificador
    # clf = RandomForestClassifier(n_estimators=50)
    clf = XGBClassifier(tree_method='gpu_hist')
    clf.fit(X_train, y_train)
    
    # Evaluación en conjunto de prueba
    y_pred = clf.predict(X_test)
    metrics["accuracy"].append(accuracy_score(y_test, y_pred))
    metrics["precision"].append(precision_score(y_test, y_pred, average="macro"))
    metrics["recall"].append(recall_score(y_test, y_pred, average="macro"))
    metrics["f1"].append(f1_score(y_test, y_pred, average="macro"))

# Mostrar resultados de validación cruzada
for metric_name, scores in metrics.items():
    print(f"{metric_name.capitalize()}: {np.mean(scores):.4f} ± {np.std(scores):.4f}")



import matplotlib.pyplot as plt

new_image = io.imread("/home/clown/3-year/computer_vision/roads/gt/10228705_15.tif")
plt.imshow(new_image, cmap="gray")
plt.show()





def predict_mask(image, model):
    features = extract_features(image)
    mask_pred = model.predict(features)
    return mask_pred.reshape(image.shape[:2])

# Generar máscara para una nueva imagen
new_image = io.imread("/home/clown/3-year/computer_vision/roads/sat/10228705_15.tiff")
mask_pred = predict_mask(new_image, clf)

# Mostrar la máscara predicha
import matplotlib.pyplot as plt
plt.imshow(mask_pred, cmap="gray")
plt.show()



# Comparar máscara predicha con ground truth
ground_truth = io.imread("/home/clown/3-year/computer_vision/p3/gt/10078675_15.tif")

accuracy = accuracy_score(ground_truth.flatten(), mask_pred.flatten())
precision = precision_score(ground_truth.flatten(), mask_pred.flatten(), average="macro")
recall = recall_score(ground_truth.flatten(), mask_pred.flatten(), average="macro")
f1 = f1_score(ground_truth.flatten(), mask_pred.flatten(), average="macro")

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")




